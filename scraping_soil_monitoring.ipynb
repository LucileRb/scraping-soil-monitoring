{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCRAPING SOIL MONITORING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faire petit résumé du notebook et de ce que fait le code\n",
    "\n",
    "TO DO -> faire une version mac / linux et une version windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tldextract in /Users/lucilerabeau/code/LucileRb/scraping-soil-monitoring/.venv/lib/python3.9/site-packages (5.1.3)\n",
      "Requirement already satisfied: idna in /Users/lucilerabeau/code/LucileRb/scraping-soil-monitoring/.venv/lib/python3.9/site-packages (from tldextract) (3.10)\n",
      "Requirement already satisfied: requests-file>=1.4 in /Users/lucilerabeau/code/LucileRb/scraping-soil-monitoring/.venv/lib/python3.9/site-packages (from tldextract) (2.1.0)\n",
      "Requirement already satisfied: filelock>=3.0.8 in /Users/lucilerabeau/code/LucileRb/scraping-soil-monitoring/.venv/lib/python3.9/site-packages (from tldextract) (3.17.0)\n",
      "Requirement already satisfied: requests>=2.1.0 in /Users/lucilerabeau/code/LucileRb/scraping-soil-monitoring/.venv/lib/python3.9/site-packages (from tldextract) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/lucilerabeau/code/LucileRb/scraping-soil-monitoring/.venv/lib/python3.9/site-packages (from requests>=2.1.0->tldextract) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/lucilerabeau/code/LucileRb/scraping-soil-monitoring/.venv/lib/python3.9/site-packages (from requests>=2.1.0->tldextract) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lucilerabeau/code/LucileRb/scraping-soil-monitoring/.venv/lib/python3.9/site-packages (from requests>=2.1.0->tldextract) (2024.12.14)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/Users/lucilerabeau/code/LucileRb/scraping-soil-monitoring/.venv/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install required librairies\n",
    "!pip install tldextract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5UBRdvav8wwK"
   },
   "outputs": [],
   "source": [
    "# Import librairies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import random\n",
    "import time\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "import sys\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options as ChromeOptions\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.proxy import *\n",
    "from selenium.webdriver.common.proxy import Proxy, ProxyType\n",
    "\n",
    "# processing\n",
    "import tldextract\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapator(search_terms, nb_pages):\n",
    "    \n",
    "    \"\"\"\n",
    "    -----------------------------------------\n",
    "    fonction pour scrapper serp google (SEO only)\n",
    "    -----------------------------------------\n",
    "    search_terms -> liste de search terms à utiliser\n",
    "    nb_pages -> nombre de pages à scrapper (int)\n",
    "    visible -> si on veut visualiser le browser ou non - par défaut = True donc visible (bool)\n",
    "    (proxy -> proxy à utiliser (WIP))\n",
    "    \n",
    "    return -> df\n",
    "    \"\"\"\n",
    "\n",
    "    start_time = datetime.now() # à formater\n",
    "    print(f'Début du programme : {start_time}\\n') # à formater\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # initier webdriver\n",
    "    options = webdriver.ChromeOptions()\n",
    "    driver = webdriver.Chrome(options = options)\n",
    "\n",
    "    print('***** scrapping en cours *****')\n",
    "\n",
    "    # boucle sur search terms\n",
    "    for term in search_terms:\n",
    "\n",
    "        print(f'\\n**** search term - {term} ****\\n')\n",
    "\n",
    "        # aller sur google\n",
    "        driver.get('https://google.com')\n",
    "\n",
    "        try:\n",
    "            WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.CSS_SELECTOR, 'button#L2AGLb.tHlp8d'))).click()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # petite pause\n",
    "        time.sleep(round(random.uniform(1, 10), 1))\n",
    "\n",
    "        # trouver la search bar\n",
    "        elem = driver.find_element(By.NAME, 'q')\n",
    "        elem.clear() # pour la vider si elle est pas vide\n",
    "\n",
    "        # entrer element de recherche dans la search bar\n",
    "        elem.send_keys(term)\n",
    "        time.sleep(2)\n",
    "        elem.send_keys(Keys.RETURN)\n",
    "\n",
    "        # petite pause\n",
    "        time.sleep(round(random.uniform(1, 10), 1))\n",
    "\n",
    "        textes = []\n",
    "        titres = []\n",
    "        url = []\n",
    "        image = []\n",
    "        page_pos = []\n",
    "        pages = []\n",
    "        seaseo = []\n",
    "        n = 0\n",
    "\n",
    "        # prendre les infos des nb_pages pages\n",
    "        while n < nb_pages:\n",
    "\n",
    "            # compteur de page\n",
    "            n += 1\n",
    "            print(f'*** -- scrapping page {n} -- ***')\n",
    "\n",
    "            # captcha\n",
    "            #recaptcha(driver)\n",
    "            time.sleep(100)\n",
    "\n",
    "            # trouver tous les articles d'une page\n",
    "            articles_SEO = driver.find_elements(By.CLASS_NAME, 'MjjYud') # -> SEO\n",
    "            articles_SEA = driver.find_elements(By.CLASS_NAME, 'uEierd') # -> SEA\n",
    "            position = 0\n",
    "\n",
    "            # boucler sur articles SEO\n",
    "            for article in articles_SEO:\n",
    "\n",
    "                try:\n",
    "                    # titre\n",
    "                    title = article.find_element(By.TAG_NAME, 'h3')\n",
    "                    titres.append(title.text)\n",
    "\n",
    "                    # position\n",
    "                    position += 1\n",
    "                    page_pos.append(position)\n",
    "\n",
    "                    # texte\n",
    "                    textes.append(article.text)\n",
    "\n",
    "                    # liens\n",
    "                    link = article.find_element(By.TAG_NAME, 'a')\n",
    "                    url.append(link.get_attribute('href'))\n",
    "\n",
    "                    # page\n",
    "                    pages.append(n)\n",
    "\n",
    "                    # type de contenu\n",
    "                    seaseo.append('SEO')\n",
    "\n",
    "                    # Image\n",
    "                    try:\n",
    "                        img = article.find_element(By.CLASS_NAME, 'Z26q7c.UK95Uc.Sth6v')\n",
    "                        image.append('Oui')\n",
    "                    except:\n",
    "                        image.append('Non')\n",
    "\n",
    "                except:\n",
    "                    titres.append('vide')\n",
    "                    page_pos.append('vide')\n",
    "                    textes.append('vide')\n",
    "                    url.append('vide')\n",
    "                    pages.append('vide')\n",
    "                    image.append('vide')\n",
    "                    seaseo.append('SEO vide')\n",
    "\n",
    "            # boucler sur articles SEA\n",
    "            position = 0\n",
    "            for add in articles_SEA:\n",
    "\n",
    "                # position\n",
    "                position += 1\n",
    "                page_pos.append(position)\n",
    "\n",
    "                # texte\n",
    "                textes.append(add.text)\n",
    "\n",
    "                # titre\n",
    "                try:\n",
    "                    title = add.find_element(By.CLASS_NAME, 'CCgQ5.vCa9Yd.QfkTvb.N8QANc.MUxGbd.v0nnCb')\n",
    "                    titres.append(title.text)\n",
    "                except:\n",
    "                    titres.append('erreur')\n",
    "\n",
    "                # liens\n",
    "                try:\n",
    "                    link = add.find_element(By.TAG_NAME, 'a')\n",
    "                    url.append(link.get_attribute('href'))\n",
    "                except:\n",
    "                    url.append('erreur')\n",
    "\n",
    "                # page\n",
    "                pages.append(n)\n",
    "\n",
    "                # type de contenu\n",
    "                seaseo.append('SEA')\n",
    "\n",
    "                try:\n",
    "                    img = add.find_element(By.CLASS_NAME, 'g-img.ZGomKf')\n",
    "                    image.append('Oui')\n",
    "                except:\n",
    "                    image.append('Non')\n",
    "\n",
    "            # se déplacer en bas de la page\n",
    "            bottom_element = driver.find_element(By.ID, 'botstuff')\n",
    "            bottom_element.location_once_scrolled_into_view\n",
    "\n",
    "            # changer de page\n",
    "            try:\n",
    "                driver.find_element(By.XPATH, (\"//*[contains(text(),'Suivant')]\")).click()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # petite pause\n",
    "            time.sleep(round(random.uniform(1, 10), 1))\n",
    "\n",
    "        # définir le bon indice à prendre quand pas le même nombre d'élements\n",
    "        if len(titres) <= len(url) and len(titres) <= len(textes):\n",
    "            size = len(titres)\n",
    "        elif len(textes) <= len(url) and len(textes) <= len(titres):\n",
    "            size = len(textes)\n",
    "        elif len(url) <= len(textes) and len(url) <= len(titres):\n",
    "            size = len(url)\n",
    "        elif len(url) == len(textes) and len(url) == len(titres) and len(textes) == len(titres):\n",
    "            print('même taille')\n",
    "            size = len(url)\n",
    "        else:\n",
    "            print('problème quelque part')\n",
    "            size = 0\n",
    "\n",
    "        # mettre le tout dans un df\n",
    "        df_term = pd.DataFrame()\n",
    "        df_term['url'] = url[0:size]\n",
    "        df_term['titles'] = titres[0:size]\n",
    "        df_term['texte'] = textes[0:size]\n",
    "        df_term['search_term'] = term\n",
    "        df_term['pages'] = pages[0:size]\n",
    "        df_term['page_position'] = page_pos[0:size]\n",
    "        df_term['type'] = seaseo[0:size]\n",
    "        df_term['images'] = image[0:size]\n",
    "\n",
    "        df_term.drop(df_term.loc[df_term['titles'] == ''].index, inplace = True)\n",
    "        df_term.reset_index(inplace = True, drop = True)\n",
    "\n",
    "        df_term['company'] = df_term['url'].apply(lambda x : tldextract.extract(x).domain)\n",
    "        df_term['domain'] = df_term['url'].apply(lambda x : urlparse(x).netloc)\n",
    "\n",
    "        # Merger avec les données des messages précédents\n",
    "        df = pd.concat([df, df_term], ignore_index = True)\n",
    "        df['Date'] = date.today().strftime('%d/%m/%y')\n",
    "\n",
    "        print(f'\\nFin du scrapping pour le search term : {term} ')\n",
    "\n",
    "    # quitter driver\n",
    "    driver.close()\n",
    "\n",
    "    end_time = datetime.now() # à formater\n",
    "    print('Duration: {}'.format(end_time - start_time)) # à formater\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RUN CODE\n",
    "The execution of the following cell will run the principal code. Please select the query you wish to enter and the number of pages you want to scrap. Then, execute the cell.\n",
    "Le programme va commencer et une nouvelle fenêtre de navigation internet va s'ouvrir. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Début du programme : 2025-02-12 22:14:17.854145\n",
      "\n",
      "***** scrapping en cours *****\n",
      "\n",
      "**** search term - Monitor* AND Report* AND Verif* AND MRV AND soil* ****\n",
      "\n",
      "*** -- scrapping page 1 -- ***\n",
      "*** -- scrapping page 2 -- ***\n",
      "\n",
      "Fin du scrapping pour le search term : Monitor* AND Report* AND Verif* AND MRV AND soil* \n",
      "Duration: 0:03:33.359429\n",
      "CPU times: user 84.9 ms, sys: 70.2 ms, total: 155 ms\n",
      "Wall time: 3min 33s\n"
     ]
    }
   ],
   "source": [
    "mots = [\n",
    "    'Monitor* AND Report* AND Verif* AND MRV AND soil*',\n",
    "    #soil monitoring reporting verification'\n",
    "    ]\n",
    "\n",
    "df = scrapator(mots, 2) # test avec 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour supprimer les lignes vides\n",
    "df = df.loc[df['url'] != 'vide']\n",
    "df = df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>titles</th>\n",
       "      <th>texte</th>\n",
       "      <th>search_term</th>\n",
       "      <th>pages</th>\n",
       "      <th>page_position</th>\n",
       "      <th>type</th>\n",
       "      <th>images</th>\n",
       "      <th>company</th>\n",
       "      <th>domain</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://scholar.google.fr/scholar?q=Monitor*+A...</td>\n",
       "      <td>Articles universitaires correspondant aux term...</td>\n",
       "      <td>Articles universitaires correspondant aux term...</td>\n",
       "      <td>Monitor* AND Report* AND Verif* AND MRV AND soil*</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Non</td>\n",
       "      <td>google</td>\n",
       "      <td>scholar.google.fr</td>\n",
       "      <td>10/02/25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>Monitor* AND Report* AND Verif* AND MRV AND soil*</td>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>SEO vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td></td>\n",
       "      <td>10/02/25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.horizon-europe.gouv.fr/monitoring-...</td>\n",
       "      <td>Monitoring, reporting and verification of soil...</td>\n",
       "      <td>Monitoring, reporting and verification of soil...</td>\n",
       "      <td>Monitor* AND Report* AND Verif* AND MRV AND soil*</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Non</td>\n",
       "      <td>horizon-europe</td>\n",
       "      <td>www.horizon-europe.gouv.fr</td>\n",
       "      <td>10/02/25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://cordis.europa.eu/programme/id/HORIZON_...</td>\n",
       "      <td>Monitoring, reporting and verification of soil...</td>\n",
       "      <td>Monitoring, reporting and verification of soil...</td>\n",
       "      <td>Monitor* AND Report* AND Verif* AND MRV AND soil*</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Non</td>\n",
       "      <td>europa</td>\n",
       "      <td>cordis.europa.eu</td>\n",
       "      <td>10/02/25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.deloitte.com/fr/fr/services/risk-a...</td>\n",
       "      <td>How to quantify, verify, and manage the impact...</td>\n",
       "      <td>How to quantify, verify, and manage the impact...</td>\n",
       "      <td>Monitor* AND Report* AND Verif* AND MRV AND soil*</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Non</td>\n",
       "      <td>deloitte</td>\n",
       "      <td>www.deloitte.com</td>\n",
       "      <td>10/02/25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>https://www.morningstar.com/news/pr-newswire/2...</td>\n",
       "      <td>TACO BELL FEATURES NEARLY 400 REAL FANS IN ITS...</td>\n",
       "      <td>TACO BELL FEATURES NEARLY 400 REAL FANS IN ITS...</td>\n",
       "      <td>Monitor* AND Report* AND Verif* AND MRV AND soil*</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Non</td>\n",
       "      <td>morningstar</td>\n",
       "      <td>www.morningstar.com</td>\n",
       "      <td>10/02/25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>https://en.wikipedia.org/wiki/Greenhouse_gas_e...</td>\n",
       "      <td>Greenhouse gas emissions by Turkey</td>\n",
       "      <td>Greenhouse gas emissions by Turkey\\nWikipedia\\...</td>\n",
       "      <td>Monitor* AND Report* AND Verif* AND MRV AND soil*</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Non</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>en.wikipedia.org</td>\n",
       "      <td>10/02/25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>https://co2re.org/research-home/mrv-socioecolo...</td>\n",
       "      <td>Monitoring, reporting and verification - CO₂RE</td>\n",
       "      <td>Monitoring, reporting and verification - CO₂RE...</td>\n",
       "      <td>Monitor* AND Report* AND Verif* AND MRV AND soil*</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Non</td>\n",
       "      <td>co2re</td>\n",
       "      <td>co2re.org</td>\n",
       "      <td>10/02/25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>Monitor* AND Report* AND Verif* AND MRV AND soil*</td>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>SEO vide</td>\n",
       "      <td>vide</td>\n",
       "      <td>vide</td>\n",
       "      <td></td>\n",
       "      <td>10/02/25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>https://www.newsngr.com.ng/2025/01/olam-agri-s...</td>\n",
       "      <td>Olam Agri: Shaping The Futureof Global Food Sy...</td>\n",
       "      <td>Olam Agri: Shaping The Futureof Global Food Sy...</td>\n",
       "      <td>Monitor* AND Report* AND Verif* AND MRV AND soil*</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Non</td>\n",
       "      <td>newsngr</td>\n",
       "      <td>www.newsngr.com.ng</td>\n",
       "      <td>10/02/25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>417 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   url  \\\n",
       "0    https://scholar.google.fr/scholar?q=Monitor*+A...   \n",
       "1                                                 vide   \n",
       "2    https://www.horizon-europe.gouv.fr/monitoring-...   \n",
       "3    https://cordis.europa.eu/programme/id/HORIZON_...   \n",
       "4    https://www.deloitte.com/fr/fr/services/risk-a...   \n",
       "..                                                 ...   \n",
       "412  https://www.morningstar.com/news/pr-newswire/2...   \n",
       "413  https://en.wikipedia.org/wiki/Greenhouse_gas_e...   \n",
       "414  https://co2re.org/research-home/mrv-socioecolo...   \n",
       "415                                               vide   \n",
       "416  https://www.newsngr.com.ng/2025/01/olam-agri-s...   \n",
       "\n",
       "                                                titles  \\\n",
       "0    Articles universitaires correspondant aux term...   \n",
       "1                                                 vide   \n",
       "2    Monitoring, reporting and verification of soil...   \n",
       "3    Monitoring, reporting and verification of soil...   \n",
       "4    How to quantify, verify, and manage the impact...   \n",
       "..                                                 ...   \n",
       "412  TACO BELL FEATURES NEARLY 400 REAL FANS IN ITS...   \n",
       "413                 Greenhouse gas emissions by Turkey   \n",
       "414     Monitoring, reporting and verification - CO₂RE   \n",
       "415                                               vide   \n",
       "416  Olam Agri: Shaping The Futureof Global Food Sy...   \n",
       "\n",
       "                                                 texte  \\\n",
       "0    Articles universitaires correspondant aux term...   \n",
       "1                                                 vide   \n",
       "2    Monitoring, reporting and verification of soil...   \n",
       "3    Monitoring, reporting and verification of soil...   \n",
       "4    How to quantify, verify, and manage the impact...   \n",
       "..                                                 ...   \n",
       "412  TACO BELL FEATURES NEARLY 400 REAL FANS IN ITS...   \n",
       "413  Greenhouse gas emissions by Turkey\\nWikipedia\\...   \n",
       "414  Monitoring, reporting and verification - CO₂RE...   \n",
       "415                                               vide   \n",
       "416  Olam Agri: Shaping The Futureof Global Food Sy...   \n",
       "\n",
       "                                           search_term pages page_position  \\\n",
       "0    Monitor* AND Report* AND Verif* AND MRV AND soil*     1             1   \n",
       "1    Monitor* AND Report* AND Verif* AND MRV AND soil*  vide          vide   \n",
       "2    Monitor* AND Report* AND Verif* AND MRV AND soil*     1             2   \n",
       "3    Monitor* AND Report* AND Verif* AND MRV AND soil*     1             3   \n",
       "4    Monitor* AND Report* AND Verif* AND MRV AND soil*     1             4   \n",
       "..                                                 ...   ...           ...   \n",
       "412  Monitor* AND Report* AND Verif* AND MRV AND soil*    50             3   \n",
       "413  Monitor* AND Report* AND Verif* AND MRV AND soil*    50             4   \n",
       "414  Monitor* AND Report* AND Verif* AND MRV AND soil*    50             5   \n",
       "415  Monitor* AND Report* AND Verif* AND MRV AND soil*  vide          vide   \n",
       "416  Monitor* AND Report* AND Verif* AND MRV AND soil*    50             6   \n",
       "\n",
       "         type images         company                      domain      Date  \n",
       "0         SEO    Non          google           scholar.google.fr  10/02/25  \n",
       "1    SEO vide   vide            vide                              10/02/25  \n",
       "2         SEO    Non  horizon-europe  www.horizon-europe.gouv.fr  10/02/25  \n",
       "3         SEO    Non          europa            cordis.europa.eu  10/02/25  \n",
       "4         SEO    Non        deloitte            www.deloitte.com  10/02/25  \n",
       "..        ...    ...             ...                         ...       ...  \n",
       "412       SEO    Non     morningstar         www.morningstar.com  10/02/25  \n",
       "413       SEO    Non       wikipedia            en.wikipedia.org  10/02/25  \n",
       "414       SEO    Non           co2re                   co2re.org  10/02/25  \n",
       "415  SEO vide   vide            vide                              10/02/25  \n",
       "416       SEO    Non         newsngr          www.newsngr.com.ng  10/02/25  \n",
       "\n",
       "[417 rows x 11 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['url', 'titles', 'texte', 'search_term', 'pages', 'page_position',\n",
       "       'type', 'images', 'company', 'domain', 'Date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Liste des colonnes du tableau de données\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les 20 domaines les plus présents dans les données\n",
    "df['domain'].value_counts()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export des résultats au format .csv\n",
    "df.to_csv('../data/scraping_results_2025-02-10.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>titles</th>\n",
       "      <th>texte</th>\n",
       "      <th>search_term</th>\n",
       "      <th>pages</th>\n",
       "      <th>page_position</th>\n",
       "      <th>type</th>\n",
       "      <th>images</th>\n",
       "      <th>company</th>\n",
       "      <th>domain</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://scholar.google.fr/scholar?q=Monitor*+A...</td>\n",
       "      <td>Articles universitaires correspondant aux term...</td>\n",
       "      <td>Articles universitaires correspondant aux term...</td>\n",
       "      <td>Monitor* AND Report* AND Verif* AND MRV AND soil*</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Non</td>\n",
       "      <td>google</td>\n",
       "      <td>scholar.google.fr</td>\n",
       "      <td>10/02/25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.horizon-europe.gouv.fr/monitoring-...</td>\n",
       "      <td>Monitoring, reporting and verification of soil...</td>\n",
       "      <td>Monitoring, reporting and verification of soil...</td>\n",
       "      <td>Monitor* AND Report* AND Verif* AND MRV AND soil*</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Non</td>\n",
       "      <td>horizon-europe</td>\n",
       "      <td>www.horizon-europe.gouv.fr</td>\n",
       "      <td>10/02/25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://cordis.europa.eu/programme/id/HORIZON_...</td>\n",
       "      <td>Monitoring, reporting and verification of soil...</td>\n",
       "      <td>Monitoring, reporting and verification of soil...</td>\n",
       "      <td>Monitor* AND Report* AND Verif* AND MRV AND soil*</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Non</td>\n",
       "      <td>europa</td>\n",
       "      <td>cordis.europa.eu</td>\n",
       "      <td>10/02/25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.deloitte.com/fr/fr/services/risk-a...</td>\n",
       "      <td>How to quantify, verify, and manage the impact...</td>\n",
       "      <td>How to quantify, verify, and manage the impact...</td>\n",
       "      <td>Monitor* AND Report* AND Verif* AND MRV AND soil*</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Non</td>\n",
       "      <td>deloitte</td>\n",
       "      <td>www.deloitte.com</td>\n",
       "      <td>10/02/25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>Solutions and insights for agricultural monito...</td>\n",
       "      <td>Solutions and insights for agricultural monito...</td>\n",
       "      <td>Monitor* AND Report* AND Verif* AND MRV AND soil*</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Non</td>\n",
       "      <td>sciencedirect</td>\n",
       "      <td>www.sciencedirect.com</td>\n",
       "      <td>10/02/25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>https://www.thenews.com.pk/print/1280468-ndc-l...</td>\n",
       "      <td>NDC lessons from the UAE and Brazil</td>\n",
       "      <td>NDC lessons from the UAE and Brazil\\nThe News ...</td>\n",
       "      <td>Monitor* AND Report* AND Verif* AND MRV AND soil*</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Non</td>\n",
       "      <td>thenews</td>\n",
       "      <td>www.thenews.com.pk</td>\n",
       "      <td>10/02/25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>https://www.morningstar.com/news/pr-newswire/2...</td>\n",
       "      <td>TACO BELL FEATURES NEARLY 400 REAL FANS IN ITS...</td>\n",
       "      <td>TACO BELL FEATURES NEARLY 400 REAL FANS IN ITS...</td>\n",
       "      <td>Monitor* AND Report* AND Verif* AND MRV AND soil*</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Non</td>\n",
       "      <td>morningstar</td>\n",
       "      <td>www.morningstar.com</td>\n",
       "      <td>10/02/25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>https://en.wikipedia.org/wiki/Greenhouse_gas_e...</td>\n",
       "      <td>Greenhouse gas emissions by Turkey</td>\n",
       "      <td>Greenhouse gas emissions by Turkey\\nWikipedia\\...</td>\n",
       "      <td>Monitor* AND Report* AND Verif* AND MRV AND soil*</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Non</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>en.wikipedia.org</td>\n",
       "      <td>10/02/25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>https://co2re.org/research-home/mrv-socioecolo...</td>\n",
       "      <td>Monitoring, reporting and verification - CO₂RE</td>\n",
       "      <td>Monitoring, reporting and verification - CO₂RE...</td>\n",
       "      <td>Monitor* AND Report* AND Verif* AND MRV AND soil*</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Non</td>\n",
       "      <td>co2re</td>\n",
       "      <td>co2re.org</td>\n",
       "      <td>10/02/25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>https://www.newsngr.com.ng/2025/01/olam-agri-s...</td>\n",
       "      <td>Olam Agri: Shaping The Futureof Global Food Sy...</td>\n",
       "      <td>Olam Agri: Shaping The Futureof Global Food Sy...</td>\n",
       "      <td>Monitor* AND Report* AND Verif* AND MRV AND soil*</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Non</td>\n",
       "      <td>newsngr</td>\n",
       "      <td>www.newsngr.com.ng</td>\n",
       "      <td>10/02/25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>385 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   url  \\\n",
       "0    https://scholar.google.fr/scholar?q=Monitor*+A...   \n",
       "1    https://www.horizon-europe.gouv.fr/monitoring-...   \n",
       "2    https://cordis.europa.eu/programme/id/HORIZON_...   \n",
       "3    https://www.deloitte.com/fr/fr/services/risk-a...   \n",
       "4    https://www.sciencedirect.com/science/article/...   \n",
       "..                                                 ...   \n",
       "380  https://www.thenews.com.pk/print/1280468-ndc-l...   \n",
       "381  https://www.morningstar.com/news/pr-newswire/2...   \n",
       "382  https://en.wikipedia.org/wiki/Greenhouse_gas_e...   \n",
       "383  https://co2re.org/research-home/mrv-socioecolo...   \n",
       "384  https://www.newsngr.com.ng/2025/01/olam-agri-s...   \n",
       "\n",
       "                                                titles  \\\n",
       "0    Articles universitaires correspondant aux term...   \n",
       "1    Monitoring, reporting and verification of soil...   \n",
       "2    Monitoring, reporting and verification of soil...   \n",
       "3    How to quantify, verify, and manage the impact...   \n",
       "4    Solutions and insights for agricultural monito...   \n",
       "..                                                 ...   \n",
       "380                NDC lessons from the UAE and Brazil   \n",
       "381  TACO BELL FEATURES NEARLY 400 REAL FANS IN ITS...   \n",
       "382                 Greenhouse gas emissions by Turkey   \n",
       "383     Monitoring, reporting and verification - CO₂RE   \n",
       "384  Olam Agri: Shaping The Futureof Global Food Sy...   \n",
       "\n",
       "                                                 texte  \\\n",
       "0    Articles universitaires correspondant aux term...   \n",
       "1    Monitoring, reporting and verification of soil...   \n",
       "2    Monitoring, reporting and verification of soil...   \n",
       "3    How to quantify, verify, and manage the impact...   \n",
       "4    Solutions and insights for agricultural monito...   \n",
       "..                                                 ...   \n",
       "380  NDC lessons from the UAE and Brazil\\nThe News ...   \n",
       "381  TACO BELL FEATURES NEARLY 400 REAL FANS IN ITS...   \n",
       "382  Greenhouse gas emissions by Turkey\\nWikipedia\\...   \n",
       "383  Monitoring, reporting and verification - CO₂RE...   \n",
       "384  Olam Agri: Shaping The Futureof Global Food Sy...   \n",
       "\n",
       "                                           search_term  pages  page_position  \\\n",
       "0    Monitor* AND Report* AND Verif* AND MRV AND soil*      1              1   \n",
       "1    Monitor* AND Report* AND Verif* AND MRV AND soil*      1              2   \n",
       "2    Monitor* AND Report* AND Verif* AND MRV AND soil*      1              3   \n",
       "3    Monitor* AND Report* AND Verif* AND MRV AND soil*      1              4   \n",
       "4    Monitor* AND Report* AND Verif* AND MRV AND soil*      1              6   \n",
       "..                                                 ...    ...            ...   \n",
       "380  Monitor* AND Report* AND Verif* AND MRV AND soil*     50              2   \n",
       "381  Monitor* AND Report* AND Verif* AND MRV AND soil*     50              3   \n",
       "382  Monitor* AND Report* AND Verif* AND MRV AND soil*     50              4   \n",
       "383  Monitor* AND Report* AND Verif* AND MRV AND soil*     50              5   \n",
       "384  Monitor* AND Report* AND Verif* AND MRV AND soil*     50              6   \n",
       "\n",
       "    type images         company                      domain      Date  \n",
       "0    SEO    Non          google           scholar.google.fr  10/02/25  \n",
       "1    SEO    Non  horizon-europe  www.horizon-europe.gouv.fr  10/02/25  \n",
       "2    SEO    Non          europa            cordis.europa.eu  10/02/25  \n",
       "3    SEO    Non        deloitte            www.deloitte.com  10/02/25  \n",
       "4    SEO    Non   sciencedirect       www.sciencedirect.com  10/02/25  \n",
       "..   ...    ...             ...                         ...       ...  \n",
       "380  SEO    Non         thenews          www.thenews.com.pk  10/02/25  \n",
       "381  SEO    Non     morningstar         www.morningstar.com  10/02/25  \n",
       "382  SEO    Non       wikipedia            en.wikipedia.org  10/02/25  \n",
       "383  SEO    Non           co2re                   co2re.org  10/02/25  \n",
       "384  SEO    Non         newsngr          www.newsngr.com.ng  10/02/25  \n",
       "\n",
       "[385 rows x 11 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lire les résultats enregistrés\n",
    "#df = pd.read_csv('../data/scraping_results_2025-02-10.csv')\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "domain\n",
       "en.wikipedia.org                 58\n",
       "co2re.org                        30\n",
       "www.newsngr.com.ng               29\n",
       "www.morningstar.com              29\n",
       "www.thenews.com.pk               29\n",
       "www.youtube.com                   6\n",
       "theoutcomesfund.com               3\n",
       "trellis.net                       2\n",
       "www.lse.ac.uk                     2\n",
       "unfccc.int                        2\n",
       "www.cesbio.cnrs.fr                2\n",
       "www.proterrafoundation.org        2\n",
       "climateactiontransparency.org     2\n",
       "www.un-redd.org                   2\n",
       "www.epa.gov                       2\n",
       "untalent.org                      2\n",
       "gggi.org                          2\n",
       "cgspace.cgiar.org                 2\n",
       "www.instagram.com                 2\n",
       "www.carbon-drawdown.de            2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
